<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>‚ö° Advanced Face & Speech Detector</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Arial', sans-serif;
            background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
            min-height: 100vh;
            color: white;
            overflow-x: hidden;
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
            padding: 15px;
        }

        .header {
            text-align: center;
            margin-bottom: 20px;
            padding: 15px;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 15px;
            backdrop-filter: blur(10px);
        }

        .header h1 {
            font-size: 2.2rem;
            margin-bottom: 8px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }

        .header p {
            font-size: 1.1rem;
            opacity: 0.9;
        }

        .main-content {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin-bottom: 20px;
        }

        @media (max-width: 768px) {
            .main-content {
                grid-template-columns: 1fr;
            }
        }

        .camera-section, .detection-section {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 15px;
            padding: 20px;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }

        .section-title {
            font-size: 1.3rem;
            margin-bottom: 15px;
            text-align: center;
            color: #fff;
        }

        .video-container {
            position: relative;
            width: 100%;
            background: #000;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 8px 32px rgba(0,0,0,0.3);
        }

        #video {
            width: 100%;
            height: 400px;
            object-fit: cover;
            transform: scaleX(-1);
        }

        .canvas-overlay {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            pointer-events: none;
        }

        .controls {
            display: flex;
            gap: 10px;
            margin-top: 15px;
            justify-content: center;
            flex-wrap: wrap;
        }

        .btn {
            padding: 10px 20px;
            border: none;
            border-radius: 20px;
            font-size: 0.9rem;
            font-weight: bold;
            cursor: pointer;
            transition: all 0.2s ease;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }

        .btn-primary {
            background: linear-gradient(45deg, #4CAF50, #45a049);
            color: white;
        }

        .btn-primary:hover {
            transform: scale(1.05);
            box-shadow: 0 4px 15px rgba(76, 175, 80, 0.4);
        }

        .btn-danger {
            background: linear-gradient(45deg, #f44336, #da190b);
            color: white;
        }

        .btn-danger:hover {
            transform: scale(1.05);
            box-shadow: 0 4px 15px rgba(244, 67, 54, 0.4);
        }

        .btn:disabled {
            background: #666;
            cursor: not-allowed;
            transform: none;
            box-shadow: none;
        }

        .detection-display {
            text-align: center;
            padding: 15px;
        }

        .expression {
            font-size: 4rem;
            margin-bottom: 15px;
            height: 100px;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.1s ease;
        }

        .expression-text {
            font-size: 2.2rem;
            font-weight: bold;
            margin-bottom: 10px;
            text-transform: capitalize;
            transition: all 0.1s ease;
        }

        .confidence {
            font-size: 1.3rem;
            margin-bottom: 15px;
            opacity: 0.9;
        }

        .status {
            font-size: 1rem;
            margin-bottom: 10px;
            padding: 8px;
            border-radius: 8px;
            background: rgba(255, 255, 255, 0.1);
        }

        .speech-indicator {
            background: linear-gradient(45deg, #ff6b6b, #ff8e8e);
            padding: 10px;
            border-radius: 20px;
            margin: 10px 0;
            font-weight: bold;
            animation: pulse 1s infinite;
        }

        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }

        .performance {
            display: flex;
            justify-content: space-around;
            margin: 15px 0;
            padding: 10px;
            background: rgba(0, 0, 0, 0.3);
            border-radius: 8px;
        }

        .performance-item {
            text-align: center;
        }

        .performance-value {
            font-size: 1.2rem;
            font-weight: bold;
            color: #4CAF50;
        }

        .landmark-info {
            background: rgba(0, 0, 0, 0.3);
            padding: 10px;
            border-radius: 8px;
            margin: 10px 0;
            font-size: 0.9rem;
        }

        .logs {
            background: rgba(0, 0, 0, 0.3);
            border-radius: 8px;
            padding: 12px;
            max-height: 150px;
            overflow-y: auto;
            margin-top: 15px;
            font-size: 0.85rem;
        }

        .log-entry {
            padding: 3px 0;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
            font-family: 'Courier New', monospace;
        }

        .footer {
            text-align: center;
            margin-top: 20px;
            padding: 15px;
            opacity: 0.7;
            font-size: 0.9rem;
        }

        .loading {
            display: none;
            text-align: center;
            padding: 15px;
        }

        .spinner {
            border: 3px solid rgba(255, 255, 255, 0.3);
            border-radius: 50%;
            border-top: 3px solid white;
            width: 30px;
            height: 30px;
            animation: spin 0.8s linear infinite;
            margin: 0 auto 8px;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        .fast-indicator {
            background: linear-gradient(90deg, #ff6b6b, #4ecdc4);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            font-weight: bold;
        }

        .dot-grid {
            display: grid;
            grid-template-columns: repeat(10, 1fr);
            gap: 2px;
            margin: 10px 0;
            padding: 10px;
            background: rgba(0, 0, 0, 0.2);
            border-radius: 8px;
        }

        .dot {
            width: 6px;
            height: 6px;
            background: #ff4444;
            border-radius: 50%;
            transition: all 0.1s ease;
        }

        .dot.active {
            background: #00ff00;
            transform: scale(1.3);
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>‚ö° Advanced Face & Speech Detector</h1>
            <p>Real-time facial landmarks, expressions, and speech detection with <span class="fast-indicator">classic red dot system</span></p>
        </div>

        <div class="main-content">
            <div class="camera-section">
                <h2 class="section-title">üìπ Live Camera Feed</h2>
                <div class="video-container">
                    <video id="video" autoplay playsinline></video>
                    <canvas id="canvas" class="canvas-overlay"></canvas>
                </div>
                <div class="controls">
                    <button id="startBtn" class="btn btn-primary">Start Detection</button>
                    <button id="stopBtn" class="btn btn-danger" disabled>Stop Detection</button>
                </div>
                
                <div class="landmark-info">
                    <h3>üî¥ Facial Landmark System</h3>
                    <p>Red dots show key facial points. Green dots indicate active movement detection.</p>
                    <div class="dot-grid" id="dotGrid">
                        <!-- Dots will be generated by JavaScript -->
                    </div>
                </div>
                
                <div class="performance">
                    <div class="performance-item">
                        <div class="performance-value" id="fpsCounter">0 FPS</div>
                        <div>Detection Speed</div>
                    </div>
                    <div class="performance-item">
                        <div class="performance-value" id="detectionTime">0ms</div>
                        <div>Processing Time</div>
                    </div>
                    <div class="performance-item">
                        <div class="performance-value" id="landmarkCount">0</div>
                        <div>Landmarks</div>
                    </div>
                </div>
                
                <div class="loading" id="loading">
                    <div class="spinner"></div>
                    <p>Loading Advanced Face & Speech Detection...</p>
                </div>
            </div>

            <div class="detection-section">
                <h2 class="section-title">üîç Real-time Analysis</h2>
                <div class="detection-display">
                    <div class="expression" id="expressionEmoji">üòê</div>
                    <div class="expression-text" id="expressionText">Neutral</div>
                    <div class="confidence" id="confidenceText">Confidence: 0%</div>
                    
                    <div id="speechIndicator" class="speech-indicator" style="display: none;">
                        üó£Ô∏è SPEAKING DETECTED!
                    </div>
                    
                    <div class="status" id="statusText">Ready for advanced detection</div>
                    
                    <div class="performance">
                        <div class="performance-item">
                            <div class="performance-value" id="mouthOpenness">0%</div>
                            <div>Mouth Open</div>
                        </div>
                        <div class="performance-item">
                            <div class="performance-value" id="headTurn">Center</div>
                            <div>Head Position</div>
                        </div>
                    </div>
                    
                    <div class="logs">
                        <h3>Activity Log</h3>
                        <div id="logContainer"></div>
                    </div>
                </div>
            </div>
        </div>

        <div class="footer">
            <p>Phistar Advanced Detection System | Facial Landmarks ‚Ä¢ Speech Detection ‚Ä¢ Real-time Analysis</p>
        </div>
    </div>

    <!-- Include TensorFlow.js and FaceAPI from CDN -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.18.0/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection@0.0.1/dist/face-landmarks-detection.min.js"></script>

    <script>
        // Global variables for advanced detection
        let video = document.getElementById('video');
        let canvas = document.getElementById('canvas');
        let ctx = canvas.getContext('2d');
        let model = null;
        let isDetecting = false;
        let detectionInterval = null;
        let currentSessionId = null;
        let frameCount = 0;
        let lastFpsUpdate = Date.now();
        let fps = 0;

        // Performance monitoring
        let detectionStartTime = 0;
        let totalDetectionTime = 0;
        let detectionCount = 0;

        // Speech detection
        let isSpeaking = false;
        let speechStartTime = 0;
        let mouthOpennessHistory = [];

        // DOM elements
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const loading = document.getElementById('loading');
        const expressionEmoji = document.getElementById('expressionEmoji');
        const expressionText = document.getElementById('expressionText');
        const confidenceText = document.getElementById('confidenceText');
        const statusText = document.getElementById('statusText');
        const logContainer = document.getElementById('logContainer');
        const fpsCounter = document.getElementById('fpsCounter');
        const detectionTime = document.getElementById('detectionTime');
        const landmarkCount = document.getElementById('landmarkCount');
        const speechIndicator = document.getElementById('speechIndicator');
        const mouthOpenness = document.getElementById('mouthOpenness');
        const headTurn = document.getElementById('headTurn');
        const dotGrid = document.getElementById('dotGrid');

        // Enhanced expression mapping
        const expressionMap = {
            'neutral': 'üòê',
            'happy': 'üòä',
            'very_happy': 'üòÑ',
            'sad': 'üò¢',
            'very_sad': 'üò≠',
            'angry': 'üò†',
            'fearful': 'üò®',
            'disgusted': 'ü§¢',
            'surprised': 'üò≤',
            'blink': 'üòë',
            'leftTurn': 'üëà',
            'rightTurn': 'üëâ',
            'up': 'üëÜ',
            'down': 'üëá',
            'smirk': 'üòè',
            'wink': 'üòâ',
            'speaking': 'üó£Ô∏è',
            'listening': 'üëÇ'
        };

        // Initialize dot grid for landmark visualization
        function initializeDotGrid() {
            dotGrid.innerHTML = '';
            for (let i = 0; i < 50; i++) {
                const dot = document.createElement('div');
                dot.className = 'dot';
                dot.id = `dot-${i}`;
                dotGrid.appendChild(dot);
            }
        }

        // Update dot grid based on facial activity
        function updateDotGrid(activityLevel, isSpeaking) {
            const dots = document.querySelectorAll('.dot');
            const activeCount = Math.floor(activityLevel * dots.length);
            
            dots.forEach((dot, index) => {
                if (index < activeCount) {
                    dot.classList.add('active');
                    if (isSpeaking) {
                        dot.style.background = '#ffaa00'; // Orange for speaking
                    } else {
                        dot.style.background = '#00ff00'; // Green for active
                    }
                } else {
                    dot.classList.remove('active');
                    dot.style.background = '#ff4444'; // Red for inactive
                }
            });
        }

        // Initialize camera with optimized settings
        async function initCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    video: { 
                        width: { ideal: 640 }, 
                        height: { ideal: 480 },
                        facingMode: 'user',
                        frameRate: { ideal: 30 }
                    } 
                });
                video.srcObject = stream;
                
                video.addEventListener('loadedmetadata', () => {
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                });
                
                log('üìπ Camera ready - Advanced detection enabled');
                return true;
            } catch (error) {
                log('‚ùå Camera error: ' + error.message, 'error');
                return false;
            }
        }

        // Load optimized face detection model
        async function loadModel() {
            try {
                loading.style.display = 'block';
                statusText.textContent = 'Loading Advanced Face & Speech Detection...';
                
                model = await faceLandmarksDetection.load(
                    faceLandmarksDetection.SupportedPackages.mediapipeFacemesh,
                    { 
                        maxFaces: 1,
                        refineLandmarks: true,
                        detectionFlips: false
                    }
                );
                
                loading.style.display = 'none';
                statusText.textContent = '‚ö° Advanced detection ready!';
                log('‚úÖ Face detection model loaded - Speech detection enabled');
                return true;
            } catch (error) {
                loading.style.display = 'none';
                log('‚ùå Model load error: ' + error.message, 'error');
                statusText.textContent = 'Failed to load model';
                return false;
            }
        }

        // Start advanced detection session
        async function startDetection() {
            try {
                const response = await fetch('/start-session', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' }
                });
                
                const data = await response.json();
                
                if (data.success) {
                    currentSessionId = data.sessionId;
                    isDetecting = true;
                    startBtn.disabled = true;
                    stopBtn.disabled = false;
                    statusText.textContent = '‚ö° Advanced detection active!';
                    log('üöÄ Advanced detection started: ' + currentSessionId);
                    
                    detectFaces();
                } else {
                    throw new Error(data.error);
                }
            } catch (error) {
                log('‚ùå Start error: ' + error.message, 'error');
            }
        }

        // Stop detection
        async function stopDetection() {
            isDetecting = false;
            cancelAnimationFrame(detectionInterval);
            
            startBtn.disabled = false;
            stopBtn.disabled = true;
            statusText.textContent = 'Detection stopped';
            speechIndicator.style.display = 'none';
            
            if (currentSessionId) {
                try {
                    await fetch('/end-session', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ sessionId: currentSessionId })
                    });
                    log('üìä Session ended: ' + currentSessionId);
                } catch (error) {
                    log('‚ùå End session error: ' + error.message, 'error');
                }
                currentSessionId = null;
            }
            
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            resetDisplay();
            updateDotGrid(0, false);
        }

        // Reset display to neutral
        function resetDisplay() {
            expressionEmoji.textContent = 'üòê';
            expressionText.textContent = 'Neutral';
            confidenceText.textContent = 'Confidence: 0%';
            mouthOpenness.textContent = '0%';
            headTurn.textContent = 'Center';
        }

        // Advanced face detection with speech recognition
        async function detectFaces() {
            if (!model || !isDetecting) return;
            
            detectionStartTime = performance.now();
            frameCount++;
            
            try {
                const predictions = await model.estimateFaces({
                    input: video,
                    returnTensors: false,
                    flipHorizontal: false,
                    predictIrises: true // Enable iris for better accuracy
                });
                
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                
                if (predictions.length > 0) {
                    const face = predictions[0];
                    drawAdvancedLandmarks(face);
                    
                    const analysis = analyzeFaceWithSpeech(face);
                    updateDisplayWithSpeech(analysis);
                    sendDetectionToServer(analysis);
                    
                    // Update performance metrics
                    landmarkCount.textContent = face.scaledMesh.length;
                    updateDotGrid(analysis.activityLevel, analysis.isSpeaking);
                } else {
                    statusText.textContent = '‚ö° No face detected';
                    resetDisplay();
                    updateDotGrid(0, false);
                }
                
                updatePerformanceMetrics();
                
            } catch (error) {
                if (error.message !== 'Cancelled') {
                    log('‚ö†Ô∏è Detection glitch: ' + error.message, 'error');
                }
            }
            
            if (isDetecting) {
                detectionInterval = requestAnimationFrame(detectFaces);
            }
        }

        // Draw advanced facial landmarks with classic red dots
        function drawAdvancedLandmarks(face) {
            const landmarks = face.scaledMesh;
            const boundingBox = face.boundingBox;
            
            // Draw bounding box
            ctx.strokeStyle = '#00ff00';
            ctx.lineWidth = 2;
            ctx.strokeRect(
                boundingBox.topLeft[0],
                boundingBox.topLeft[1],
                boundingBox.bottomRight[0] - boundingBox.topLeft[0],
                boundingBox.bottomRight[1] - boundingBox.topLeft[1]
            );
            
            // Draw key facial points as red dots
            ctx.fillStyle = '#ff0000';
            
            // Key facial landmarks (simplified set for performance)
            const keyPoints = [
                // Eyes
                33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246,
                362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398,
                // Eyebrows
                55, 65, 52, 53, 46, 285, 295, 282, 283, 276,
                // Nose
                1, 2, 98, 327,
                // Mouth (important for speech)
                61, 84, 17, 314, 405, 320, 307, 81, 82, 13, 312, 311, 310, 415, 95, 88,
                78, 191, 80, 81, 82, 87, 14, 317, 402, 318, 324, 308,
                // Face contour
                10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, 378, 400
            ];
            
            keyPoints.forEach(index => {
                if (landmarks[index]) {
                    const point = landmarks[index];
                    ctx.beginPath();
                    ctx.arc(point[0], point[1], 2, 0, 2 * Math.PI);
                    ctx.fill();
                }
            });
            
            // Draw mouth outline for speech visualization
            drawMouthOutline(landmarks);
        }

        // Draw mouth outline for speech detection visualization
        function drawMouthOutline(landmarks) {
            const mouthPoints = [61, 84, 17, 314, 405, 320, 307, 81, 82, 13, 312, 311, 310, 415, 95, 88, 78];
            
            ctx.strokeStyle = isSpeaking ? '#ffaa00' : '#00ff00';
            ctx.lineWidth = 2;
            ctx.beginPath();
            
            mouthPoints.forEach((index, i) => {
                const point = landmarks[index];
                if (point) {
                    if (i === 0) {
                        ctx.moveTo(point[0], point[1]);
                    } else {
                        ctx.lineTo(point[0], point[1]);
                    }
                }
            });
            
            ctx.closePath();
            ctx.stroke();
        }

        // Advanced facial analysis with speech detection
        function analyzeFaceWithSpeech(face) {
            const landmarks = face.scaledMesh;
            
            // Get key points
            const noseTip = landmarks[1];
            const mouthLeft = landmarks[61];
            const mouthRight = landmarks[291];
            const mouthTop = landmarks[13];
            const mouthBottom = landmarks[14];
            const leftEye = landmarks[33];
            const rightEye = landmarks[263];
            const leftEyebrow = landmarks[65];
            const rightEyebrow = landmarks[295];
            
            let expression = 'neutral';
            let confidence = 0.8;
            let additionalInfo = 'Face detected';
            let activityLevel = 0;
            
            // Calculate mouth openness for speech detection
            const mouthWidth = Math.abs(mouthRight[0] - mouthLeft[0]);
            const mouthHeight = Math.abs(mouthBottom[1] - mouthTop[1]);
            const currentMouthOpenness = (mouthHeight / mouthWidth) * 100;
            
            // Update mouth openness history for speech detection
            mouthOpennessHistory.push(currentMouthOpenness);
            if (mouthOpennessHistory.length > 10) {
                mouthOpennessHistory.shift();
            }
            
            // Speech detection logic
            const avgMouthOpenness = mouthOpennessHistory.reduce((a, b) => a + b) / mouthOpennessHistory.length;
            const mouthOpennessVariation = Math.max(...mouthOpennessHistory) - Math.min(...mouthOpennessHistory);
            
            isSpeaking = avgMouthOpenness > 15 && mouthOpennessVariation > 5;
            
            if (isSpeaking) {
                expression = 'speaking';
                confidence = 0.9;
                additionalInfo = 'SPEAKING DETECTED - Mouth movement active';
                activityLevel = 0.8;
            }
            // Enhanced expression detection
            else {
                // Smile detection
                const smileIntensity = (mouthWidth / 80) + (mouthHeight / 20);
                
                if (smileIntensity > 2.5) {
                    expression = 'very_happy';
                    confidence = Math.min(0.95, smileIntensity / 3);
                    additionalInfo = 'BIG SMILE!';
                    activityLevel = 0.7;
                } else if (smileIntensity > 1.8) {
                    expression = 'happy';
                    confidence = Math.min(0.85, smileIntensity / 2.5);
                    additionalInfo = 'Smiling detected';
                    activityLevel = 0.6;
                }
                // Sad detection
                else {
                    const eyebrowAngle = (leftEyebrow[1] - landmarks[65][1]) + (rightEyebrow[1] - landmarks[295][1]);
                    const mouthCornersDown = (mouthLeft[1] - landmarks[61][1]) + (mouthRight[1] - landmarks[291][1]);
                    
                    if (eyebrowAngle > 10 && mouthCornersDown > 5) {
                        expression = 'very_sad';
                        confidence = 0.8;
                        additionalInfo = 'SAD expression';
                        activityLevel = 0.6;
                    } else if (eyebrowAngle > 5) {
                        expression = 'sad';
                        confidence = 0.7;
                        additionalInfo = 'Slightly sad';
                        activityLevel = 0.5;
                    }
                }
            }
            
            // Head movement detection
            let headPosition = 'Center';
            if (noseTip[0] < canvas.width * 0.35) {
                expression = 'leftTurn';
                headPosition = 'Left';
                activityLevel = 0.9;
            } else if (noseTip[0] > canvas.width * 0.65) {
                expression = 'rightTurn';
                headPosition = 'Right';
                activityLevel = 0.9;
            } else if (noseTip[1] < canvas.height * 0.35) {
                expression = 'up';
                headPosition = 'Up';
                activityLevel = 0.7;
            } else if (noseTip[1] > canvas.height * 0.65) {
                expression = 'down';
                headPosition = 'Down';
                activityLevel = 0.7;
            }
            
            return {
                expression: expression,
                confidence: confidence,
                additionalInfo: additionalInfo,
                landmarks: landmarks.slice(0, 10),
                isSpeaking: isSpeaking,
                mouthOpenness: currentMouthOpenness,
                headPosition: headPosition,
                activityLevel: activityLevel
            };
        }

        // Enhanced display update with speech indicators
        function updateDisplayWithSpeech(analysis) {
            const emoji = expressionMap[analysis.expression] || 'üòê';
            const expressionName = analysis.expression.replace('_', ' ').toUpperCase();
            
            expressionEmoji.textContent = emoji;
            expressionText.textContent = expressionName;
            confidenceText.textContent = `Confidence: ${Math.round(analysis.confidence * 100)}%`;
            statusText.textContent = analysis.additionalInfo;
            mouthOpenness.textContent = `${Math.round(analysis.mouthOpenness)}%`;
            headTurn.textContent = analysis.headPosition;
            
            // Speech indicator
            if (analysis.isSpeaking) {
                speechIndicator.style.display = 'block';
                expressionEmoji.style.transform = 'scale(1.2)';
                expressionText.style.color = '#ffaa00';
            } else {
                speechIndicator.style.display = 'none';
                expressionEmoji.style.transform = 'scale(1)';
                expressionText.style.color = 'white';
            }
        }

        // Send enhanced detection to server
        async function sendDetectionToServer(analysis) {
            if (!currentSessionId) return;
            
            fetch('/detect-expression', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    sessionId: currentSessionId,
                    expression: analysis.expression,
                    confidence: analysis.confidence,
                    landmarks: analysis.landmarks,
                    isSpeaking: analysis.isSpeaking,
                    mouthOpenness: analysis.mouthOpenness
                })
            }).catch(() => {});
        }

        // Performance monitoring
        function updatePerformanceMetrics() {
            const now = Date.now();
            const currentDetectionTime = performance.now() - detectionStartTime;
            
            totalDetectionTime += currentDetectionTime;
            detectionCount++;
            
            if (now - lastFpsUpdate >= 1000) {
                fps = frameCount;
                frameCount = 0;
                lastFpsUpdate = now;
                
                const avgDetectionTime = totalDetectionTime / detectionCount;
                
                fpsCounter.textContent = `${fps} FPS`;
                detectionTime.textContent = `${avgDetectionTime.toFixed(1)}ms`;
                
                totalDetectionTime = 0;
                detectionCount = 0;
            }
        }

        // Fast logging
        function log(message, type = 'info') {
            const logEntry = document.createElement('div');
            logEntry.className = 'log-entry';
            logEntry.textContent = `[${new Date().toLocaleTimeString()}] ${message}`;
            
            if (type === 'error') {
                logEntry.style.color = '#ff6b6b';
            } else if (type === 'success') {
                logEntry.style.color = '#51cf66';
            }
            
            logContainer.appendChild(logEntry);
            
            if (logContainer.children.length > 10) {
                logContainer.removeChild(logContainer.firstChild);
            }
            
            logContainer.scrollTop = logContainer.scrollHeight;
        }

        // Event listeners
        startBtn.addEventListener('click', startDetection);
        stopBtn.addEventListener('click', stopDetection);

        // Advanced initialization
        async function init() {
            log('üöÄ Initializing Advanced Face & Speech Detector...');
            initializeDotGrid();
            
            const cameraReady = await initCamera();
            if (!cameraReady) return;
            
            const modelReady = await loadModel();
            if (!modelReady) return;
            
            log('‚úÖ READY! Advanced detection with speech recognition active');
            statusText.textContent = '‚ö° Ready - Click Start for Advanced Detection';
        }

        // Start the advanced application
        init();
    </script>
</body>
</html>
